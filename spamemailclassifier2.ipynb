{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimahb/spam-email-classifier/blob/main/spamemailclassifier2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2PuS9OxOgMSq",
        "outputId": "d4d72a2a-bd3b-4728-a3b5-8f6473e2e55e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VsPjfu3iIpH"
      },
      "outputs": [],
      "source": [
        "#load dataset\n",
        "spam_df = pd.read_csv('/content/spam data.csv')\n",
        "\n",
        "#convert to dataframe\n",
        "spam_df = pd.DataFrame(spam_df, columns=['text', 'label'])\n",
        "\n",
        "#shuffle data\n",
        "spam_df = spam_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "#stopwords common words to remove\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "#preprocess texts\n",
        "def clean_text(text):\n",
        "  if not isinstance(text, str):  # Convert non-strings to empty string\n",
        "        text = \"\"\n",
        "  words = word_tokenize(text.lower())  # Tokenize & lowercase\n",
        "  return [word for word in words if word.isalpha() and word not in stop_words]\n",
        "\n",
        "\n",
        "# Apply cleaning\n",
        "spam_df[\"processed_text\"] = spam_df[\"text\"].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2hxwXNkmWd2",
        "outputId": "334a1419-4619-44c0-9bb7-ca610a6a7b2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All Words Sample: ['using', 'tomcat', 'need', 'need', 'support', 'web', 'services', 'security', 'get', 'stuff']\n"
          ]
        }
      ],
      "source": [
        "from nltk import FreqDist\n",
        "# Get most common words\n",
        "all_words = [word for words in spam_df[\"processed_text\"] for word in words]\n",
        "word_features = list(FreqDist(all_words).keys())[:2000]\n",
        "\n",
        "# Check if we got words\n",
        "print(\"All Words Sample:\", all_words[:10])  # Should print some words\n",
        "\n",
        "\n",
        "# Function to convert text into features\n",
        "def document_features(words):\n",
        "    words = set(words)\n",
        "    return {word: (word in words) for word in word_features}\n",
        "\n",
        "# Convert dataset into feature sets\n",
        "featuresets = [(document_features(words), label) for words, label in zip(spam_df[\"processed_text\"], spam_df[\"label\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ3xPgZnoG_D",
        "outputId": "ed9df379-f044-496a-ce0e-eb840924c3ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 88.54%\n"
          ]
        }
      ],
      "source": [
        "#train the naivebayes model\n",
        "from nltk import NaiveBayesClassifier\n",
        "from nltk.classify import accuracy\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset (80% train, 20% test)\n",
        "train_set, test_set = train_test_split(featuresets, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "# Test model\n",
        "accuracy_score = accuracy(classifier, test_set)\n",
        "print(f\"Accuracy: {accuracy_score * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY6s2wnarI_I",
        "outputId": "dc1d4a85-5142-4042-b355-4ad0c0e8b64f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 10 Word Features: ['author', 'kai', 'date', 'escapenumber', 'mon', 'jun', 'new', 'revision', 'websvn', 'http']\n"
          ]
        }
      ],
      "source": [
        "print(\"First 10 Word Features:\", word_features[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_saIxJ1yL3i",
        "outputId": "e1c6db3c-0128-414b-f95a-72ed7b7d2a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "ham\n"
          ]
        }
      ],
      "source": [
        "#sample emails\n",
        "emails = ['michael pobega wrote i\\'m not sure if it\\'s the mpl or mozilla that didn\\'t allow the distribution of their images or the patching of programs without their knowledge but i think that is not dfsg free last time i looked the mozilla images were in an other licenses directory so not under the mpl and not licensed to others at all hope that helps mjr slef my opinion only see http people debian org mjr please follow']\n",
        "processed_email = clean_text(emails[0])\n",
        "email_features = document_features(processed_email)\n",
        "\n",
        "make_predictions = classifier.classify(email_features)\n",
        "print(make_predictions)\n",
        "\n",
        "if make_predictions == 1:\n",
        "  print(\"spam\")\n",
        "else:\n",
        "  print('ham')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhI28-FsAAvf",
        "outputId": "07cd0094-c0db-47c1-f5a5-644049eab61a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['spam_classifier.pkl']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create and fit TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=2000)  # You can adjust max_features\n",
        "vectorizer.fit(spam_df[\"text\"])  # Fit to your text data\n",
        "\n",
        "# Save the vectorizer\n",
        "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
        "\n",
        "joblib.dump(classifier, 'spam_classifier.pkl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BKoisGphB9m2",
        "outputId": "c15db477-4043-4655-c0f9-43c9e3535dec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi nest-asyncio pyngrok uvicorn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lx_g8Z4CJ9K",
        "outputId": "42fb2315-7bf2-4277-baaa-ba3699a60f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-10 (run):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-20-d4f66e598a1e>\", line 30, in run\n",
            "NameError: name 'uvicorn' is not defined\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Public URL: NgrokTunnel: \"https://46cf-146-148-107-171.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        }
      ],
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import joblib\n",
        "\n",
        "# Apply nested event loop patch for Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Load the trained model and vectorizer\n",
        "model = joblib.load(\"spam_classifier.pkl\")\n",
        "vectorizer = joblib.load(\"vectorizer.pkl\")\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class EmailText(BaseModel):\n",
        "    text: str\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "def predict_spam(data: EmailText):\n",
        "    transformed_text = vectorizer.transform([data.text])\n",
        "    prediction = model.predict(transformed_text)\n",
        "    label = \"spam\" if prediction[1] == 0 else \"not spam\"\n",
        "    return {\"prediction\": label}\n",
        "\n",
        "from threading import Thread\n",
        "!ngrok authtoken 2vMgmtnlQzUPNRkWRxM5hXwjdKV_546Deti2Ad6Fm8tU9ZQz9\n",
        "\n",
        "def run():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "t = Thread(target=run)\n",
        "t.start()\n",
        "\n",
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Set up a tunnel to the FastAPI server\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"Public URL:\", public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KT8qxuDWLmt_",
        "outputId": "8af8a94f-db55-4ebf-d44b-6b11666d9f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.44.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.33.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Streamlit app is live at: NgrokTunnel: \"https://235f-146-148-107-171.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://146.148.107.171:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "\n",
        "import streamlit as st\n",
        "import requests\n",
        "\n",
        "with open('app.py', 'w') as f:\n",
        "  f.write(\"\"\"\n",
        "st.title('Spam Email Classification')\n",
        "st.write(\"This is a sample Streamlit app for spam email classification!\")\n",
        "\n",
        "st.title(\"📧 Spam Email Classifier\")\n",
        "email = st.text_area(\"Enter email content:\")\n",
        "\n",
        "if st.button(\"Classify\"):\n",
        "    response = requests.post(API_URL, json={\"text\": email})\n",
        "    prediction = response.json()[\"prediction\"]\n",
        "    st.success(f\"The email is classified as: **{prediction.upper()}**\")\"\"\")\n",
        "\n",
        " #Expose Streamlit app using ngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Set up a tunnel to the Streamlit app (port 8501 is the default Streamlit port)\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app is live at: {public_url}\")\n",
        "\n",
        "\n",
        "API_URL = \"http://localhost:8000/\"\n",
        "\n",
        "!streamlit run app.py &  # Run Streamlit in the background"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmGK6DVwSyxBrunzlzE8ni",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}